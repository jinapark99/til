# ğŸ—“ï¸ 2025-08-01 (FRI)

> **Today I learned**  
What it truly means to understand how the internet communicates, from the foundational protocols to practical web scraping using Python.  
I didn't just learn to code â€” I learned to interpret, question, and reconstruct how machines talk to each other, and how I can guide them step by step.

---

## ğŸŒ Internet & Web Communication â€“ Questions I Asked

Throughout today (and yesterday), I explored foundational web concepts not by memorizing, but by **relentlessly asking why**. Some of the major questions I asked and understood deeply:

### â“ Who created all this? Where did these ideas come from?

- I asked: *â€œWho first imagined this whole system of invisible connections and layered protocols?â€*
- I learned that the internet isnâ€™t just a machine thing â€” itâ€™s a human design:
  - **Paul Baran** (RAND): Invented packet switching (data chopped into pieces)
  - **Vint Cerf & Bob Kahn**: Designed **TCP/IP**, the heart of internet communication
  - **Tim Berners-Lee** (CERN): Invented **HTML** and the **World Wide Web** in 1989
- These werenâ€™t just programmers â€” they were **architects of connection itself**.
- And now I use their legacy in 5 lines of Python.

---

### â“ What is a socket? Why do we use `socket.socket()`?
- A socket is like a **virtual phone line** â€” it lets two computers talk.
- `socket.socket()` creates the socket; the first `socket` is the module, the second is the class.
- Analogy: `socket.socket()` = "Get me a telephone from the telephone toolbox."

### â“ What do `AF_INET` and `SOCK_STREAM` mean?
- `AF_INET` â†’ IPv4 address format (like house addresses)
- `SOCK_STREAM` â†’ TCP protocol = safe delivery (like hand-delivering a message)
- These define how data flows â€” reliably (TCP) or just fast (UDP).

---

### â“ What is a byte? Why do we encode and decode?

- A byte is a group of **8 bits**, the smallest building block of data (like a Lego brick).
- But the **meaning** of that byte depends on the encoding standard used.

#### ğŸ”¤ Common Byte Encodings:

| Encoding | Description |
|----------|-------------|
| **ASCII** | 7-bit English-only standard (e.g., 'A' = 65) |
| **UTF-8** | Variable-length (1â€“4 bytes), can represent all characters in the world |
| **UTF-16** | 2 bytes for most characters, sometimes 4 |
| **UTF-32** | Fixed 4 bytes per character (simple, but wasteful) |

âœ… **Today, UTF-8 is the dominant standard.**  
Itâ€™s used by over 95% of websites and is Pythonâ€™s default in most cases.

#### ğŸ§  How Python handles it:
- `encode()` = string (Unicode) â†’ bytes
- `decode()` = bytes â†’ string (Unicode)
- `ord()` & `chr()` help map characters to their numeric codes (Unicode points)

---

### â“ Why are SSL errors ignored sometimes?

- Websites use certificates (SSL) to prove theyâ€™re secure.
- But for scraping, expired/mismatched certs block access.

```python
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE
```

---

### â“ What is HTML parsing and why is it hard?
- Webpages look clean in a browser but are often messy in HTML.
- Tags are unclosed, deeply nested, or dynamically generated.
- I asked why BeautifulSoup exists â†’ to fix and structure messy HTML.

### ğŸ§  So what is a parser?
A parser is a translator that turns raw HTML text into structured elements (tree-like).
It lets Python say things like:

- "Get me all the <a> tags"
- "Pull the value of the href attribute"
- "Grab the contents inside a tag"

---

### ğŸ§ª BeautifulSoup + urllib â€“ Practical Learning
After building intuition, I used BeautifulSoup and urllib to:

- Retrieve a webpage
- Parse all <a> (anchor) tags
- Extract the href attribute
- Traverse the Nth link, M times
- Print the final name on the last page

## âœ… Final Code: Follow Nth Link M Times
```python
import urllib.request
from bs4 import BeautifulSoup
import ssl

ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

url = input('Enter URL: ')
count = int(input('Enter count: '))
position = int(input('Enter position: '))

for i in range(count):
    html = urllib.request.urlopen(url, context=ctx).read()
    soup = BeautifulSoup(html, 'html.parser')
    tags = soup('a')
    url = tags[position - 1].get('href')

html = urllib.request.urlopen(url, context=ctx).read()
soup = BeautifulSoup(html, 'html.parser')
print('Last name:', soup.title.string)
````

---

### ğŸ’¡ Insight â€“ What I Realized
I donâ€™t need to memorize syntax. What matters is knowing the structure and flow.
Iâ€™m not afraid to ask small, foundational questions like:

- â€œWhy does decode need utf-8?â€
- â€œWhy is data a byte, not a string?â€
- The internet is layered: from hardware â†’ protocol â†’ string â†’ meaning.
- Even a simple line like tag.contents[0] hides a rich structure beneath it.
- I also learned that websites often block scrapers with JS, dynamic HTML, or timing tricks â€” and that BeautifulSoup or Selenium can overcome them.

---

### ğŸ”— Topics Covered
Who invented the internet and HTML? (Paul Baran, Vint Cerf, Tim Berners-Lee)

- Sockets: what they are, how to use them
- IP, ports, and TCP/UDP communication
- Byte structure, encoding/decoding, Unicode, UTF-8
- HTML structure and parser basics
- urllib for HTTP requests
- BeautifulSoup for HTML parsing
- Navigating <a> links repeatedly
- Extracting attributes cleanly


