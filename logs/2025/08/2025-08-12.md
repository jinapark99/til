# üóìÔ∏è 2025-08-12 (TUE)

> **Today I Learned**  
> While working on the AI eye-tracking project for HyoLim Medical Foundation, I identified fundamental limitations in the current webcam-based setup, which led me to rethink the model‚Äôs design direction.

---

## üì∑ Project Context ‚Äì AI Eye Tracking for Medical Use
The main objective was to detect whether the participant's gaze successfully follows a red dot moving across the screen. This is intended to assess eye movement accuracy and responsiveness.

---

## ‚ö†Ô∏è Limitations Identified

### 1. **Low Camera Resolution**
- Current webcam input size: **640 √ó 480 pixels**.
- This resolution results in very small on-screen movement for the red dot when converted to pixel coordinates.
- Even when the dot moves from one screen edge to the other, the captured movement appears minimal, making it difficult to analyze meaningful gaze patterns.

**Impact:**  
The test loses sensitivity unless the participant sits **very close** to the camera.

---

### 2. **Unrealistic Testing Conditions**
- The need to move extremely close to the camera is impractical for real-world medical testing.
- Day-to-day variance in seating distance makes the measurement inconsistent.

---

### 3. **Distance Normalization Challenge**
- Idea: Measure the **eye corner-to-corner distance** in the camera feed.
- Use this distance ratio compared to a baseline photo to estimate **how close the face is** to the camera on each trial.
- Problem:  
  - Uncertainty about whether the scaling calculation is being correctly applied in the code.
  - Difficult to ensure the distance normalization logic is accurate.

---

### 4. **Pixel Scale Mismatch**
- The **camera‚Äôs captured pixel space** and the **monitor‚Äôs display pixel space** differ.
- This mismatch means a movement measured in camera pixels does not directly match movement in monitor pixels.
- To fix this:
  - Need to calculate the **pixel scaling ratio** between the monitor and camera.
  - Apply this ratio before generating final CSV output.

---

### 5. **CSV Output & Vector Calculation Limitation**
- Goal: Output a CSV containing the **scaled, normalized position data** for further analysis.
- Current challenge: The vector comparison between the gaze point and the red dot is **not reliable** due to the resolution and scaling issues.

---

## üí° Rethinking the Approach
Instead of strictly checking ‚ÄúDid the gaze match the moving red dot?‚Äù, consider focusing on **eye movement behavior analysis**:
- Detect **movement amplitude** over time (regardless of exact match to dot).
- Identify **sudden gaze jumps** or **latency** in movement.
- Check for **asymmetry** between left and right eye motion.
- Analyze **coordination**: Are both eyes moving together?

This may provide **more realistic and useful medical indicators** than exact gaze tracking in this setup.

---

## üîç Reflection
- Current method is technically possible but **environmentally unrealistic** for patients.
- Shifting from pixel-perfect matching to **pattern-based eye movement analysis** could yield more robust results.
- Next step: Redesign the model logic to prioritize movement patterns over exact coordinate tracking.

