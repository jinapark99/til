# 🗓️ 2025-08-17 (SUN)

> **Today I learned** about how data flows from text files into
> databases and finally into visualization on a map, and how these
> concepts connect to my own Parkinson's project. Also reviewed parsing,
> query strings, and how peer-graded assignments work in Coursera.

------------------------------------------------------------------------

## 📘 Python / Database / Visualization

### Flow Recap (from lecture)

-   **Input**: `where.data` (addresses)\
-   **Process**:
    -   `geoload.py` → check DB → call API if not found → save results
        into `geodata.sqlite`
    -   `geodump.py` → dump DB into `where.js`
-   **Output**: `where.html` uses `where.js` to show markers on a map

### Code Details

``` python
address = line.strip()
cur.execute("SELECT geodata FROM Locations WHERE address=?", 
            (memoryview(address.encode()), ))
```

-   `strip()` → remove whitespace/newlines from each line
-   `encode()` → convert string → bytes (for DB safety)
-   `memoryview()` → pass bytes to SQLite efficiently and safely
-   If not found in DB → build query string, call API, store response

------------------------------------------------------------------------

## 🌐 Query String

-   Web servers understand parameters via **query string** in a URL:

        https://maps.googleapis.com/maps/api/geocode/json?q=Seoul+City+Hall

-   Built from Python dict:

    ``` python
    parms = {'q': address}
    urllib.parse.urlencode(parms)  # "q=Seoul+City+Hall"
    ```

👉 This is necessary because URLs cannot contain raw spaces or special
characters.

------------------------------------------------------------------------

## 🔎 Parsing

-   **Parsing** = break down raw data into structured pieces for use
-   Examples:
    -   **URL parsing** → scheme, host, path, query
    -   **JSON parsing** → raw string → Python dict

👉 Like sorting LEGO blocks before building something.

------------------------------------------------------------------------

## 📊 Project Connection (Parkinson's severity)

-   In this assignment → visualize **locations** on a map
-   In my project → visualize **severity scores** over time
-   Pipeline is the same:
    -   Input: motion/voice/eye data\
    -   Process: model inference → severity score\
    -   Save: SQLite DB\
    -   Output: charts (line graph for progression, bar chart for
        comparison, heatmap for affected body parts)

------------------------------------------------------------------------

## 🎓 Coursera Peer-Graded Assignments

-   Submission requires:
    -   Upload 3 screenshots (`geoload.py`, `geodump.py`, `where.html`)
    -   Review at least 3 peers
-   My peers graded me all 4/4 (full credit) ✅
-   Flag button = report inappropriate review (not needed if feedback is
    normal)

------------------------------------------------------------------------

## 💡 Insights

-   API is just one "data provider" --- in my own projects, the provider
    can be my AI model.
-   Query strings are like "search instructions" for servers.
-   Parsing turns messy data into structured data I can actually use.
-   The assignment's pipeline (file → DB → visualization) is a pattern I
    can reuse for Parkinson's severity visualization.

------------------------------------------------------------------------

## 📝 Reflection

Today helped me connect a simple location-visualization assignment to my
Parkinson's project.\
I now clearly see how **data ingestion, storage, and visualization**
work as a pipeline, and how I can swap out "location" with "severity
score."

I also reinforced my understanding of parsing, query strings, and why
encoding is needed when saving strings into DB.\
Even Coursera's peer review process gave me insight: learning isn't just
coding, but also reviewing and giving feedback constructively.
